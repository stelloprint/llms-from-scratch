{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32154917",
   "metadata": {},
   "source": [
    "# From Appendix A: Introduction to PyTorch\n",
    "\n",
    "[https://livebook.manning.com/book/build-a-large-language-model-from-scratch/appendix-a](link to live Manning book).\n",
    "\n",
    "## Understanding Tensors\n",
    "\n",
    "Listing A.1 Creating PyTorch tensors\n",
    "Note: matrices and above are indented to make them easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd98b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create tensors of different dimensions\n",
    "\n",
    "tensor0d = torch.tensor(1)\n",
    "\n",
    "tensor1d = torch.tensor([1, 2, 3])\n",
    "\n",
    "tensor2d = torch.tensor([[1, 2], \n",
    "                                     [3, 4]])\n",
    "                                     \n",
    "tensor3d = torch.tensor([[[1, 2], [3, 4]], \n",
    "                                     [[5, 6], [7, 8]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec2689",
   "metadata": {},
   "source": [
    "##  Tensor Data Types\n",
    "\n",
    "This choice is primarily due to the balance between precision and computational efficiency. A 32-bit floating-point number offers sufficient precision for most deep learning tasks while consuming less memory and computational resources than a 64-bit floating-point number. Moreover, GPU architectures are optimized for 32-bit computations, and using this data type can significantly speed up model training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tensor0d.dtype:', tensor0d.dtype) # dtype: torch.int64\n",
    "print('tensor1d:', tensor1d)\n",
    "print('tensor2d:', tensor2d)\n",
    "print('tensor3d:', tensor3d)\n",
    "print('tensor3d.shape:', tensor3d.shape)\n",
    "\n",
    "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
    "print('floatvec.dtype:', floatvec.dtype) # dtype: torch.float32\n",
    "print('floatvec:', floatvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201247f",
   "metadata": {},
   "source": [
    "It is possible to change the precision using a tensor’s .to method. The following code demonstrates this by changing a 64-bit integer tensor into a 32-bit float tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "floatvec2 = tensor3d.to(torch.float32)\n",
    "print('floatvec2.dtype:', floatvec2.dtype) # dtype: torch.float32\n",
    "print('floatvec2:', floatvec2)\n",
    "\n",
    "# Common Pytorch Tensor Operations\n",
    "\n",
    "# Create Tensor\n",
    "tensor2d = torch.tensor([[1, 2, 3], \n",
    "                         [4, 5, 6]])\n",
    "\n",
    "print('tensor2d:', tensor2d) # Output: tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# .shape returns [2, 3], meaning the tensor has two rows and three columns\n",
    "print('tensor2d.shape:', tensor2d.shape) # Output: torch.Size([2, 3])\n",
    "\n",
    "# To reshape the tensor into a 3 × 2 tensor, we can use the .reshape method\n",
    "print('tensor2d.reshape(3, 2):', tensor2d.reshape(3, 2)) # Output: tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# The more common command for reshaping tensors in PyTorch is .view():\n",
    "print('tensor2d.view(3, 2):', tensor2d.view(3, 2)) # Output: tensor([[1, 2], [3, 4], [5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9786b",
   "metadata": {},
   "source": [
    "Similar to `.reshape` and `.view`, in several cases, PyTorch offers multiple syntax options for executing the same computation. PyTorch initially followed the original Lua Torch syntax convention but then, by popular request, added syntax to make it similar to NumPy. (The subtle difference between `.view()` and `.reshape()` in PyTorch lies in their handling of memory layout: `.view()` requires the original data to be contiguous and will fail if it isn’t, whereas `.reshape()` will work regardless, copying the data if necessary to ensure the desired shape.)\n",
    "\n",
    "Next, we can use `.T` to transpose a tensor, which means flipping it across its diagonal. \n",
    "\n",
    "Note that this is not the same as reshaping a tensor, as you can see based on the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a485068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tensor2d.T:', tensor2d.T)\n",
    "\n",
    "# The output is tensor([[1, 4], [2, 5], [3, 6]])\n",
    "\n",
    "# Lastly, the common way to multiply two matrices in PyTorch is the .matmul method:\n",
    "\n",
    "print('tensor2d.matmul(tensor2d.T):', tensor2d.matmul(tensor2d.T))\n",
    "\n",
    "# The output is tensor([[14, 32], [32, 77]])\n",
    "\n",
    "# However, we can also adopt the @ operator, which accomplishes the same thing more compactly:\n",
    "\n",
    "print('tensor2d @ tensor2d.T:', tensor2d @ tensor2d.T)\n",
    "\n",
    "# The output is tensor([[14, 32], [32, 77]])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
