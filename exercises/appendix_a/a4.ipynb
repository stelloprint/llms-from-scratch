{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6e1adf",
   "metadata": {},
   "source": [
    "# A.4 Automatic Differentiation Made Easy\n",
    "\n",
    " If we carry out computations in PyTorch, it will build a computational graph internally by default if one of its terminal nodes has the requires_grad attribute set to True. This is useful if we want to compute gradients. Gradients are required when training neural networks via the popular backpropagation algorithm, which can be considered an implementation of the chain rule from calculus for neural networks.\n",
    "\n",
    "The most common way of computing the loss gradients in a computation graph involves applying the chain rule from right to left, also called reverse-model automatic differentiation or backpropagation. We start from the output layer (or the loss itself) and work backward through the network to the input layer. We do this to compute the gradient of the loss with respect to each parameter (weights and biases) in the network, which informs how we update these parameters during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a374c3",
   "metadata": {},
   "source": [
    "## Partial derivatives and gradients\n",
    "\n",
    "Partial derivatives measure the rate at which a function changes with respect to one of its variables. A gradient is a vector containing all of the partial derivatives of a multivariate function, a function with more than one variable as input.\n",
    "\n",
    "The chain rule is a way to compute gradients of a loss function given the model’s parameters in a computation graph. This provides the information needed to update each parameter to minimize the loss function, which serves as a proxy for measuring the model’s performance using a method such as gradient descent. \n",
    "\n",
    "PyTorch’s autograd engine constructs a computational graph in the background by tracking every operation performed on tensors. Then, calling the grad function, we can compute the gradient of the loss concerning the model parameter w1, as shown in the following listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.0]) # label\n",
    "x1 = torch.tensor([1.1]) # input\n",
    "w1 = torch.tensor([2.2], requires_grad=True) # weight\n",
    "b = torch.tensor([0.0], requires_grad=True) # bias\n",
    "\n",
    "z = x1 * w1 + b # linear combination\n",
    "a = torch.sigmoid(z) # sigmoid activation\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y) # binary cross entropy loss\n",
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True) # gradient of loss with respect to w1\n",
    "grad_L_b = grad(loss, b, retain_graph=True) # gradient of loss with respect to b"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
